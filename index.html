<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Zorik Gekhman</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Zorik Gekhman</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile2.jpeg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#selectedpublications">Selected Publications</a></li>
		    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#allpublications">All Publications</a></li>
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li> -->
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
		
        <div class="container-fluid p-0">
	
			
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Zorik Gekhman
                    </h1>
				
					<p class="lead mb-5"> 
						I am a Computer Science PhD student at the <a href="https://cs.technion.ac.il/">Technion</a> under the supervision of <a href="https://roireichart.com/">Roi Reichart</a>. I am also in my second year as a research intern at <a href="https://research.google/">Google Research</a>, where I am supervised by <a href="https://jonathanherzig.github.io/">Jonathan Herzig</a> and <a href="https://roeeaharoni.com/">Roee Aharoni</a>.
					</p>
                    <p class="lead mb-5">
					I work on the robustness and interpretability of large language models, with a focus on factuality and hallucinations. My research develops rigorous methods to evaluate robustness, explores the underlying causes of robustness issues, and proposes strategies to mitigate them.
					</p>
					<h4>Past</h4>
					<p class="lead mb-5">
					I worked as a full time Research Engineer at <a href="https://health.google/health-research/">Google Health Research</a> for 4 years, and as a backend engineer at Microsoft for 3 years.
					</p>
					<p class="lead mb-5">
					I hold a BSc. in Computer Science from the <a href="https://cs.technion.ac.il/">Technion</a> (Summa Cum Laude). I served 6 years as an Air Traffic Controller officer in the Israeli Air Force (Major).
					</p>
					<div class="social-icons">
                        
                        <a class="social-icon" href="https://scholar.google.com/citations?user=c748UcIAAAAJ"><i class="ai ai-google-scholar"></i></a>
			<a class="social-icon" href="https://x.com/zorikgekhman"><i class="fab fa-twitter"></i></a>
			<a class="social-icon" href="https://www.linkedin.com/in/zorik-gekhman-b60330107//"><i class="fab fa-linkedin-in"></i></a>
                        
                    </div>
			<p class="lead mb-5" style="margin-top: 1rem;">
    <img src="./assets/email_icon.webp" alt="email icon" width="45" height="50"> 
    <a href="mailto:zorikgekhman@gmail.com">zorikgekhman@gmail.com</a>
			</p>		
                </div>
            </section>
            <hr class="m-0" />
			
			<!-- Selected Publications -->
			
			<section class="resume-section" id="selectedpublications">
                <div class="resume-section-content">
                    <h2 class="mb-5">Selected Publications</h2>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig</span>
        </h4>
        <div class="subheading">EMNLP 2024</div>
        <p>
            We study the impact of introducing new factual knowledge during fine-tuning, on the LLM's capability to utilize its pre-existing knowledge, acquired during pre-training. We show that LLMs struggle to learn new knowledge through fine-tuning, but when they eventually do, it linearly increases their tendency to hallucinations w.r.t. their pre-existing knowledge.  Our findings highlight the potential for unintended consequences when introducing new knowledge through fine-tuning, and imply that fine-tuning may be more useful as a mechanism to enhance the utilization of pre-existing knowledge.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2405.05904" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/new_knowledge/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Jonathan Herzig, Roee Aharoni, Chen Elkind, Idan Szpektor</span>
        </h4>
        <div class="subheading">EMNLP 2023</div>
        <p>
            To train models that can evaluate factual consistency in summarization, we need labeled training data—comprising document-summary pairs labeled for consistency—which is unavailable in the summarization domain. As a result, existing models heavily rely on synthetic data, where negative (inconsistent) examples are created by perturbing human-written summaries to inject errors. However, this approach results in (1) limited coverage of possible errors, as perturbation logic is usually simple, and (2) an unnatural data distribution, as perturbed summaries differ from model-generated ones. To address these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a large language model (LLM). Unlike prior work, TrueTeacher does not rely on human-written summaries and is inherently multilingual, with the resulting summaries contain more realistic errors and a natural text distribution. We release a large-scale synthetic dataset (1.4M examples) generated using TrueTeacher, along with a model checkpoint trained on this data.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2023.emnlp-main.127.pdf" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/google/t5_11b_trueteacher_and_anli" target="_blank" rel="noopener">Model</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/datasets/google/trueteacher" target="_blank" rel="noopener">Data</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/trueteacher/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2023</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u><sup>*</sup>, Nadav Oved<sup>*</sup>, Orgad Keller, Idan Szpektor, Roi Reichart</span>
        </h4>
        <div class="subheading">TACL 2023</div>
        <p>
            Most works on modeling the conversation history in Conversational Question Answering (CQA) report a single main result on a common CQA benchmark. While existing models show impressive results on CQA leaderboards, it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g. from large to small sets) and domain. In this work, we design and conduct the first large-scale robustness study of history modeling approaches for CQA. We find that high benchmark scores do not necessarily translate to strong robustness, and that various methods can perform extremely differently under different settings. Equipped with the insights from our study, we design a novel prompt-based history modeling approach and demonstrate its strong robustness across various settings.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2206.14796" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/zorikg/MarCQAp" target="_blank" rel="noopener">Code</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/marcqap/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2023</span></div>
</div>


			


                </div>
            </section>
            <hr class="m-0" />




<!-- All Publications -->
			
<section class="resume-section" id="allpublications">
<div class="resume-section-content">
<h2 class="mb-5">All Publications</h2>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig</span>
        </h4>
        <div class="subheading">EMNLP 2024</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2405.05904" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/new_knowledge/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations</h3>
        <h4>
                <span style="font-weight: normal;">Hadas Orgad, Michael Toker, <u>Zorik Gekhman</u>, Roi Reichart, Idan Szpektor, Hadas Kotek, Yonatan Belinkov</span>
        </h4>
        <div class="subheading">Preprint</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2410.02707" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/llms_know/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>NL-Eye: Abductive NLI for Images</h3>
        <h4>
                <span style="font-weight: normal;">Mor Ventura, Michael Toker, Nitay Calderon, <u>Zorik Gekhman</u>, Yonatan Bitton, Roi Reichart</span>
        </h4>
        <div class="subheading">Preprint</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2410.02613" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/nl_eye/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>

	

<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Measuring the Robustness of NLP Models to Domain Shifts</h3>
        <h4>
                <span style="font-weight: normal;">Nitay Calderon<sup>*</sup>, Naveh Porat<sup>*</sup>, Eyal Ben-David, Alexander Chapanin, <u>Zorik Gekhman</u>, Nadav Oved, Vitaly Shalumov, Roi Reichart</span>
        </h4>
        <div class="subheading">Findings of EMNLP 2024</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2306.00168" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/domain_robustness/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Can LLMs Learn Macroeconomic Narratives from Social Media?</h3>
        <h4>
                <span style="font-weight: normal;">Almog Gueta, Amir Feder, <u>Zorik Gekhman</u>, Ariel Goldstein, Roi Reichart</span>
        </h4>
        <div class="subheading">Preprint</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2406.12109" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/mcroeconomics/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Jonathan Herzig, Roee Aharoni, Chen Elkind, Idan Szpektor</span>
        </h4>
        <div class="subheading">EMNLP 2023</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2023.emnlp-main.127.pdf" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/google/t5_11b_trueteacher_and_anli" target="_blank" rel="noopener">Model</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/datasets/google/trueteacher" target="_blank" rel="noopener">Data</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/trueteacher/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2023</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u><sup>*</sup>, Nadav Oved<sup>*</sup>, Orgad Keller, Idan Szpektor, Roi Reichart</span>
        </h4>
        <div class="subheading">TACL 2023</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2206.14796" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/zorikg/MarCQAp" target="_blank" rel="noopener">Code</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/marcqap/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2023</span></div>
</div>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Using Text Injection to Improve Recognition of Personal Identifiers in Speech</h3>
        <h4>
                <span style="font-weight: normal;">Yochai Blau, Rohan Agrawal, Lior Madmony, Gary Wang, Andrew Rosenberg, Zhehuai Chen, <u>Zorik Gekhman</u>, Genady Beryozkin, Parisa Haghani, Bhuvana Ramabhadran</span>
        </h4>
        <div class="subheading">INTERSPEECH 2023</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.isca-archive.org/interspeech_2023/blau23_interspeech.pdf" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/text_injection/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2023</span></div>
</div>

	

<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>RED-ACE: Robust Error Detection for ASR using Confidence Embeddings</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u><sup>*</sup>, Dina Zverinski<sup>*</sup>, Jonathan Mallinson, Genady Beryozkin</span>
        </h4>
        <div class="subheading">EMNLP 2022</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2022.emnlp-main.180.pdf" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/google-research/google-research/tree/master/red-ace" target="_blank" rel="noopener">Code</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/marcqap/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2022</span></div>
</div>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>KoBE: : Knowledge-Based Machine Translation Evaluation</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Roee Aharoni ,Genady Beryozkin, Markus Freitag, Wolfgang Macherey</span>
        </h4>
        <div class="subheading">Findings of EMNLP 2020</div>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2020.findings-emnlp.287.pdf" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/google-research/google-research/tree/master/kobe" target="_blank" rel="noopener">Code and Data</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/kobe/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2020</span></div>
</div>


			


</div>
</section>
<hr class="m-0" />



            
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
		<!-- Load jQuery, SimpleModal and Basic JS files -->
		<script type='text/javascript' src='js/jquery.js'></script>
		<script type='text/javascript' src='js/jquery.simplemodal.js'></script>
		<script type='text/javascript' src='js/basic.js'></script>
		
    </body>
</html>
