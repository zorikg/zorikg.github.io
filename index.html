<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Zorik Gekhman</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Zorik Gekhman</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.jpeg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li> -->
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
		
        <div class="container-fluid p-0">
	
			
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Hadas Orgad
                    </h1>
				
					<p class="lead mb-5"> I am currently pursuing my Ph.D. in the field of Natural Language Processing at the <a href="https://cs.technion.ac.il/">Technion-Israel Institute of Technology</a> under the supervision of <a href="https://roireichart.com/">Roi Reichart</a>.</p>
                    <p class="lead mb-5">
					My research focus is on interpretability of large language models, exploring how they encode linguistic and factual information about the world. My primary focus lies in leveraging interpretability as a strategic tool for enhancing model performance, specifically addressing robustness and safety concerns, with the ultimate goal of improving transparency and trustworthiness. Thus, my work revolves around developing new methods for evaluating, understanding and improving the robustness of NLP models, ultimately aiming to create models that are both powerful and responsible.
					</p>
                    <p class="lead mb-5"><b>Feel free to reach out</b> 
					if you're interested in brainstorming or exploring potential collaboration opportunities with me. </p>
					<h4>Past</h4>
					<p class="lead mb-5">
					I recently interned at Apple. Before that, I worked at Microsoft for 3.5 years (software engineering and later research).
					</p>
					<p class="lead mb-5">
					I completed my bachelors and my masters in the Technion. During masters, I was selected for the 2022 EMEA Generation Google Scholarship.
					Previously, I worked in Microsoft, for the cloud security research, where I worked on data-science problems and on the application of NLP for security products.
					</p>
					<div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/hadas-orgad/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/orgadhadas"><i class="fab fa-github"></i></a>
                        <a class="social-icon" href="https://twitter.com/OrgadHadas"><i class="fab fa-twitter"></i></a>
                        <a class="social-icon" href="https://scholar.google.com/citations?user=xWntyLkAAAA"><i class="ai ai-google-scholar"></i></a>
                    </div>
					<p class="lead mb-5" style="margin-top: 1rem;"> <img src="./assets/email_icon.webp" alt="email icon" width="45" height="50"> orgadhadas at gmail dot com </p>
                </div>
            </section>
            <hr class="m-0" />
			
			<!-- Publications -->
			
			<section class="resume-section" id="publications">
                <div class="resume-section-content">
                    <h2 class="mb-5">Selected Publications</h2>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig</span>
        </h4>
        <div class="subheading">EMNLP 2024</div>
        <p>
            We study the impact of introducing new factual knowledge during fine-tuning, on the LLM's capability to utilize its pre-existing knowledge, acquired during pre-training. We show that LLMs struggle to learn new knowledge through fine-tuning, but when they eventually do, it linearly increases their tendency to hallucinations w.r.t. their pre-existing knowledge.  Our findings highlight the potential for unintended consequences when introducing new knowledge through fine-tuning, and imply that fine-tuning may be more useful as a mechanism to enhance the utilization of pre-existing knowledge.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2405.05904" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/new_knowledge/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u>, Jonathan Herzig, Roee Aharoni, Chen Elkind, Idan Szpektor</span>
        </h4>
        <div class="subheading">EMNLP 2023</div>
        <p>
            To train models that can evaluate factual consistency in summarization, labeled training data—comprising document-summary pairs labeled for consistency—is required, but such data is unavailable in the summarization domain. As a result, existing models heavily rely on synthetic data, where negative (inconsistent) examples are created by perturbing human-written summaries to inject errors. However, this approach results in (1) limited coverage of possible errors, as perturbation logic is usually simple, and (2) an unnatural data distribution, as perturbed summaries differ from model-generated ones. To address these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a large language model (LLM). Unlike prior work, TrueTeacher does not rely on human-written summaries and is inherently multilingual. The resulting summaries contain more realistic errors and a natural text distribution. Experiments on the TRUE benchmark show that a student model trained on our data substantially outperforms both the state-of-the-art model of similar capacity and the LLM teacher. In a systematic study, we compare TrueTeacher to existing synthetic data generation methods, demonstrating its superiority and robustness to domain shift. Additionally, we show that our method generalizes to multilingual scenarios. Finally, we release a large-scale synthetic dataset (1.4M examples) generated using TrueTeacher, along with a model checkpoint trained on this data.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2023.emnlp-main.127.pdf" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/google/t5_11b_trueteacher_and_anli" target="_blank" rel="noopener">Model</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://huggingface.co/datasets/google/trueteacher" target="_blank" rel="noopener">Data</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/trueteacher/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>



<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method</h3>
        <h4>
                <span style="font-weight: normal;"><u>Zorik Gekhman</u><sup>*</sup>, Nadav Oved<sup>*</sup>, Orgad Keller, Idan Szpektor, Roi Reichart</span>
        </h4>
        <div class="subheading">TACL 2023</div>
        <p>
            Most works on modeling the conversation history in Conversational Question Answering (CQA) report a single main result on a common CQA benchmark. While existing models show impressive results on CQA leaderboards, it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g. from large to small sets) and domain. In this work, we design and conduct the first large-scale robustness study of history modeling approaches for CQA. We find that high benchmark scores do not necessarily translate to strong robustness, and that various methods can perform extremely differently under different settings. Equipped with the insights from our study, we design a novel prompt-based history modeling approach and demonstrate its strong robustness across various settings.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2206.14796" target="_blank" rel="noopener">Paper</a>
	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/zorikg/MarCQAp" target="_blank" rel="noopener">Code</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/marcqap/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>


			


                </div>
            </section>
            <hr class="m-0" />
		
			
            
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
		<!-- Load jQuery, SimpleModal and Basic JS files -->
		<script type='text/javascript' src='js/jquery.js'></script>
		<script type='text/javascript' src='js/jquery.simplemodal.js'></script>
		<script type='text/javascript' src='js/basic.js'></script>
		
    </body>
</html>
