<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Zorik Gekhman</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Zorik Gekhman</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.jpeg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li> -->
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li> -->
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
		
        <div class="container-fluid p-0">
	
			
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Hadas Orgad
                    </h1>
				
					<p class="lead mb-5"> I am currently pursuing my Ph.D. in the field of Natural Language Processing at the <a href="https://cs.technion.ac.il/">Technion-Israel Institute of Technology</a> under the supervision of <a href="https://roireichart.com/">Roi Reichart</a>.</p>
                    <p class="lead mb-5">
					My research focus is on interpretability of large language models, exploring how they encode linguistic and factual information about the world. My primary focus lies in leveraging interpretability as a strategic tool for enhancing model performance, specifically addressing robustness and safety concerns, with the ultimate goal of improving transparency and trustworthiness. Thus, my work revolves around developing new methods for evaluating, understanding and improving the robustness of NLP models, ultimately aiming to create models that are both powerful and responsible.
					</p>
                    <p class="lead mb-5"><b>Feel free to reach out</b> 
					if you're interested in brainstorming or exploring potential collaboration opportunities with me. </p>
					<h4>Past</h4>
					<p class="lead mb-5">
					I recently interned at Apple. Before that, I worked at Microsoft for 3.5 years (software engineering and later research).
					</p>
					<p class="lead mb-5">
					I completed my bachelors and my masters in the Technion. During masters, I was selected for the 2022 EMEA Generation Google Scholarship.
					Previously, I worked in Microsoft, for the cloud security research, where I worked on data-science problems and on the application of NLP for security products.
					</p>
					<div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/hadas-orgad/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/orgadhadas"><i class="fab fa-github"></i></a>
                        <a class="social-icon" href="https://twitter.com/OrgadHadas"><i class="fab fa-twitter"></i></a>
                        <a class="social-icon" href="https://scholar.google.com/citations?user=xWntyLkAAAA"><i class="ai ai-google-scholar"></i></a>
                    </div>
					<p class="lead mb-5" style="margin-top: 1rem;"> <img src="./assets/email_icon.webp" alt="email icon" width="45" height="50"> orgadhadas at gmail dot com </p>
                </div>
            </section>
            <hr class="m-0" />
			
			<!-- Publications -->
			
			<section class="resume-section" id="publications">
                <div class="resume-section-content">
                    <h2 class="mb-5">Publications</h2>


<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
    <div class="flex-grow-1">
        <h3>Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</h3>
        <h4>
                <strong>Zorik Gekhman</strong>, <span style="font-weight: normal;">Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig</span>
        </h4>
        <div class="subheading">EMNLP 2024</div>
        <p>
            We study the impact of introducing new factual knowledge through fine-tuning, on the LLM's capability to utilize its pre-existing knowledge, acquired during pre-training. We show that LLMs struggle to learn new knowledge through fine-tuning, but when they eventually learn this new knowledge, it leads to a higher tendency to hallucinations.
        </p>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2405.05904" target="_blank" rel="noopener">Paper</a>
        <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/new_knowledge/cite.bib" target="_blank" rel="noopener">Cite</a>
    </div>
    <div class="flex-shrink-0"><span class="text-primary">2024</span></div>
</div>
			
	
								
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3>TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models</h3>
							<h4> Dana Arad*, Hadas Orgad*, Yonatan Belinkov </h4>
                            <div class="subheading">EMNLP 2023</div>
                            <p>We introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM, which does not rely on human-written summaries, and is multilingual by nature.</p>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2023.emnlp-main.127.pdf" target="_blank" rel="noopener">Paper</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/ReFACT/cite.bib" target="_blank" rel="noopener">Cite</a>
						</div>
						<div class="flex-shrink-0"><span class="text-primary">2023</span></div>
					</div>



			
					<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3>Unified Concept Editing in Diffusion Models</h3>
							<h4> Rohit Gandikota, Hadas Orgad, Yonatan Belinkov, Joanna Materzy≈Ñska, David Bau </h4>
                            <div class="subheading">IEEE/CVF WACV 2024</div>
                            <p>
							Text-to-image models suffer from various safety issues that may limit their suitability for deployment. Previous methods have separately addressed individual issues of bias, copyright, and offensive content in text-to-image models. However, in the real world, all of these issues appear simultaneously in the same model.
							In this paper, we present a method that tackles those diverse issues with a single approach.</p>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://unified.baulab.info/" target="_blank" rel="noopener">Project Page</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2308.14761" target="_blank" rel="noopener">Arxiv</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/UCE/cite.bib" target="_blank" rel="noopener">Cite</a>
						</div>
						<div class="flex-shrink-0"><span class="text-primary">2023</span></div>
					</div>
					
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3>Editing Implicit Assumptions in Text-to-Image Diffusion Models</h3>
							<h4> Hadas Orgad*, Bahjat Kawar*, Yonatan Belinkov </h4>
                            <div class="subheading">ICCV 2023</div>
                            <p>
							Text-to-image diffusion models often make implicit assumptions about the world when generating images. While some assumptions are useful (e.g., the sky is blue), they can also be outdated, incorrect, or reflective of social biases present in the training data.
							In this work, we aim to edit a given implicit assumption in a pre-trained diffusion model.
							Our method is highly efficient, as it modifies a mere 2.2% of the model's parameters in under one second.
							</p>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://time-diffusion.github.io/" target="_blank" rel="noopener">Project Page</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2303.08084" target="_blank" rel="noopener">Arxiv</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/TIME/cite.bib" target="_blank" rel="noopener">Cite</a>
						</div>
						<div class="flex-shrink-0"><span class="text-primary">2023</span></div>
					</div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3>Debiasing NLP Models Without Demographic Information</h3>
							<h4> Hadas Orgad, Yonatan Belinkov </h4>
                            <div class="subheading">ACL 2023</div>
                            <p>
							In this work, we propose a debiasing method that operates without any prior knowledge of the demographics in the dataset, detecting biased examples based on an auxiliary model that predicts the main model's success and down-weights them during the training process. Results on racial and gender bias demonstrate that it is possible to mitigate social biases without having to use a costly demographic annotation process.
							</p>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2212.10563" target="_blank" rel="noopener">Arxiv</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/Debiasing-NLP-Models-Without-Demographic-Information/cite.bib" target="_blank" rel="noopener">Cite</a>
						</div>
						<div class="flex-shrink-0"><span class="text-primary">2022</span></div>
					</div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Choose your lenses: Flaws in gender bias evaluation</h3>
							<h4> Hadas Orgad, Yonatan Belinkov </h4>
                            <div class="subheading mb-3">GeBNLP 2022</div>
                            <p>Considerable efforts to measure and mitigate gender bias in recent years have led to the introduction of an abundance of tasks, datasets, and metrics used in this vein. In this position paper, we assess the current paradigm of gender bias evaluation and identify several flaws in it.</p>
                        	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2022.gebnlp-1.17/" target="_blank" rel="noopener">Arxiv</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/Choose-Your-Lenses/cite.bib" target="_blank" rel="noopener">Cite</a>
						</div>
                        <div class="flex-shrink-0"><span class="text-primary">2022</span></div>
                    </div>
					<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">How Gender Debiasing Affects Internal Model Representations, and Why It Matters</h3>
							<h4>Hadas Orgad, Seraphina Goldfarb-Tarrant, Yonatan Belinkov</h4>
                            <div class="subheading mb-3">NAACL 2022</div>
                            <p>Common studies of gender bias in NLP focus either on extrinsic bias measured by model performance on a downstream task or on intrinsic bias found in models‚Äô internal representations. However, the relationship between extrinsic and intrinsic bias is relatively unknown. In this work, we illuminate this relationship by measuring both quantities together.</p>
                        	<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aclanthology.org/2022.naacl-main.188/" target="_blank" rel="noopener">Arxiv</a>
							<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="./publications/How-Gender-Debiasing-Affects-Internal-Model-Representations/cite.bib" target="_blank" rel="noopener">Cite</a>
						</div>
                        <div class="flex-shrink-0"><span class="text-primary">2022</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
		
			
            
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
		<!-- Load jQuery, SimpleModal and Basic JS files -->
		<script type='text/javascript' src='js/jquery.js'></script>
		<script type='text/javascript' src='js/jquery.simplemodal.js'></script>
		<script type='text/javascript' src='js/basic.js'></script>
		
    </body>
</html>
